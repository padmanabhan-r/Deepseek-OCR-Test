{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nimport torch\n\nmodel_name = 'deepseek-ai/DeepSeek-OCR'\n\nprint(\"Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\nprint(\"Loading model (this will take 3-5 minutes)...\")\nmodel = AutoModel.from_pretrained(\n    model_name, \n    trust_remote_code=True, \n    use_safetensors=True,\n    attn_implementation='eager'\n)\nmodel = model.eval().cuda().to(torch.bfloat16)\nprint(\"✓ Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:11:21.975507Z","iopub.execute_input":"2025-10-23T16:11:21.976290Z","iopub.status.idle":"2025-10-23T16:13:10.580041Z","shell.execute_reply.started":"2025-10-23T16:11:21.976257Z","shell.execute_reply":"2025-10-23T16:13:10.579348Z"}},"outputs":[{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c00df06d37f745778f9deab362947676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1460424b9d48437e9e90ce1c3e7f3766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/801 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"482cd4f54ebc46b59a2c6b9e19583d1c"}},"metadata":{}},{"name":"stdout","text":"Loading model (this will take 3-5 minutes)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b3cbaab1124b52ac05a0f34ceee40d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_deepseekocr.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2337fc199f08496aa184ec63edc5c771"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conversation.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5fb4d2fffc042d5bd46919fccd52caf"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n- conversation.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"deepencoder.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59d8b9d11f2b4fcd92006c60a3fe5cbb"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n- deepencoder.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_deepseekv2.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb827d825b96434598eb0cb755d6652a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_deepseek_v2.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1a6d49a9d344469f1e6fb9b868cecb"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n- configuration_deepseek_v2.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n- modeling_deepseekv2.py\n- configuration_deepseek_v2.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n- modeling_deepseekocr.py\n- conversation.py\n- deepencoder.py\n- modeling_deepseekv2.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n2025-10-23 16:11:38.541387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761235898.935745      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761235899.056613      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nYou are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e26b231282154e24bb81a1372154fd4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67487512738416e95149792bf818caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-000001.safetensors:   0%|          | 0.00/6.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11e2e2485cd547708bca0e2461df5475"}},"metadata":{}},{"name":"stderr","text":"Some weights of DeepseekOCRForCausalLM were not initialized from the model checkpoint at deepseek-ai/DeepSeek-OCR and are newly initialized: ['model.vision_model.embeddings.position_ids']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"✓ Model loaded successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\n# Your uploaded file will be in /kaggle/input/\n# List files to see the exact path\nprint(\"Available files:\")\nfor root, dirs, files in os.walk('/kaggle/input/'):\n    for file in files:\n        print(os.path.join(root, file))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:13:15.265964Z","iopub.execute_input":"2025-10-23T16:13:15.266792Z","iopub.status.idle":"2025-10-23T16:13:15.279052Z","shell.execute_reply.started":"2025-10-23T16:13:15.266752Z","shell.execute_reply":"2025-10-23T16:13:15.278374Z"}},"outputs":[{"name":"stdout","text":"Available files:\n/kaggle/input/sample-image/sample.jpg\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Update this with your actual filename\nimage_file = '/kaggle/input/sample-image/sample.jpg'\n\nos.makedirs('/kaggle/working/out', exist_ok=True)\n\n# prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\nprompt = \"Extrat the text as json\"\nprint(f\"\\nProcessing image...\")\n\nres = model.infer(\n    tokenizer, \n    prompt=prompt, \n    image_file=image_file, \n    output_path='/kaggle/working/out', \n    base_size=1024, \n    image_size=640, \n    crop_mode=True, \n    save_results=True, \n    test_compress=True\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"OCR RESULT:\")\nprint(\"=\"*60)\nprint(res)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Results saved to: /kaggle/working/out\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:18:42.401991Z","iopub.execute_input":"2025-10-23T16:18:42.402670Z","iopub.status.idle":"2025-10-23T16:19:09.406573Z","shell.execute_reply.started":"2025-10-23T16:18:42.402645Z","shell.execute_reply":"2025-10-23T16:19:09.405835Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image...\n=====================\nBASE:  torch.Size([1, 256, 1280])\nPATCHES:  torch.Size([6, 100, 1280])\n=====================\n\nThe角和角度的关系图\n\nThe Proof of Innocence\n\nDmitri Krioukov\n\n1 Cooperative Association for Internet Data Analysis (CAIDA),\n\nUniversity of California, San Diego (UCSD), La Jolla, CA 92093, USA\n\nWe show that if a car stops at a stop sign, an observer, e.g., a police officer, located at a certain\n\ndistance perpendicular to the car trajectory, must have an illusion that the car does not stop, if the\n\nfollowing three conditions are satisfied: (1) the observer measures not the linear but angular speed\n\nof the car; (2) the car decelerates and subsequently accelerates relatively fast; and (3) there is a\n\nshort-time obstruction of the observer's view of the car by an external object, e.g., another car, at\n\nthe moment when both cars are near the stop sign.\n\nI.INTRODUCTION\n\nC(car)\n\nS(stop sign)\n\nL(lane)\n\nIt is widely known that an observer measuring the\n\nspeed of an object passing by, measures not its actual\n\nlinear velocity by the angular one. For example, if we\n\nstay not far away from a railroad, watching a train ap-\n\nproaching us from far away at a constant speed, we first\n\nperceive the train not moving at all, when it is really far,\n\nbut when the train comes closer, it appears to us mov-\n\ning faster and faster, and when it actually passes us, its\n\nvisual speed is maximized.\n\nThis observation is the first building block of our proof\n\nof innocence. To make this proof rigorous, we first con-\n\nsider the relationship between the linear and angular\n\nspeeds of an object in the toy example where the ob-\n\nject moves at a constant linear speed. We then proceed\n\nto analyzing a picture reflecting what really happened\n\nin the considered case, that is, the case where the linear\n\nspeed of an object is not constant, but what is constant\n\ninstead is the deceleration and subsequent acceleration of\n\nthe object coming to a complete stop at a point located\n\nclosest to the observer on the object's linear trajectory.\n\nFinally, in the last section, we consider what happens\n\nat that critical moment the observer's view is briefly\n\nII. CONSTANT LINEAR SPEED\n\nTo express a(t) in terms of r and x(t) we observe from\n\ntriangle OCS that\n\nConsider Fig. 1 schematically showing the geometry of\n\nthe considered case, and assume for a moment that C's\n\nlinear velocity is constant in time t,\n\n(4)\n\nv(t) = vo.\n\nleading to\n\nWithout loss of generality we can choose time units t such\n\nthat t = 0 corresponds to the moment when C is at S.\n\nThen distance x is simply\n\nSubstituting the last expression into Eq. (3) and using\n\nthe standard differentiation rules there, i.e., specifically\n\nthe fact that\n\nbut its angular speed given by the first derivative of an-\n\n(5)\n\nwhere f(t) is any function of t, but it is f(t) = vot/r0\n\n(3)\n\nhere, we find that the angular speed of C that O observes\n\n============================================================\nOCR RESULT:\n============================================================\nNone\n\n============================================================\nResults saved to: /kaggle/working/out\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}